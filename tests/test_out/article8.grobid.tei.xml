<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Framing the News: From Human Perception to Large Language Model Inferences</title>
				<funder ref="#_Cr9Hj8B">
					<orgName type="full">European Commission</orgName>
				</funder>
				<funder ref="#_SaYavCd">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>ACM</publisher>
				<availability status="unknown"><p>Copyright ACM</p>
				</availability>
				<date type="published" when="2023-06-12">2023-06-12</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">David</forename><surname>Alonso Del Barrio</surname></persName>
							<idno type="ORCID">0000-0002-6728-6774</idno>
						</author>
						<author>
							<persName coords="2,500.92,62.77,57.28,6.23"><forename type="first">Daniel</forename><surname>Gatica-Perez</surname></persName>
							<idno type="ORCID">0000-0001-5488-2182</idno>
							<affiliation key="aff1">
								<orgName type="institution">Idiap Research Institute</orgName>
								<address>
									<country>EPFL Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Framing the News: From Human Perception to Large Language Model Inferences</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2023 ACM International Conference on Multimedia Retrieval</title>
						<meeting>the 2023 ACM International Conference on Multimedia Retrieval						</meeting>
						<imprint>
							<publisher>ACM</publisher>
							<date type="published" when="2023-06-12" />
						</imprint>
					</monogr>
					<idno type="MD5">0EA09E3C8AF11042A3A13F897F23C8E7</idno>
					<idno type="DOI">10.1145/3591106.3592278</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-02-03T02:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Covid-19 no-vax</term>
					<term>news framing</term>
					<term>GPT-3</term>
					<term>prompt-engineering</term>
					<term>transformers</term>
					<term>large language models</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Identifying the frames of news is important to understand the articles' vision, intention, message to be conveyed, and which aspects of the news are emphasized. Framing is a widely studied concept in journalism, and has emerged as a new topic in computing, with the potential to automate processes and facilitate the work of journalism professionals. In this paper, we study this issue with articles related to the Covid-19 anti-vaccine movement. First, to understand the perspectives used to treat this theme, we developed a protocol for human labeling of frames for 1786 headlines of No-Vax movement articles of European newspapers from 5 countries. Headlines are key units in the written press, and worth of analysis as many people only read headlines (or use them to guide their decision for further reading.) Second, considering advances in Natural Language Processing (NLP) with large language models, we investigated two approaches for frame inference of news headlines: first with a GPT-3.5 fine-tuning approach, and second with GPT-3.5 prompt-engineering. Our work contributes to the study and analysis of the performance that these models have to facilitate journalistic tasks like classification of frames, while understanding whether the models are able to replicate human perception in the identification of these frames.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS CONCEPTS</head><p>• Computing methodologies → Information extraction; • Human-centered computing → Text input.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>In recent years, there has been a proliferation in the use of concepts such as data journalism, computational journalism, and computerassisted reporting <ref type="bibr" coords="1,385.41,221.87,14.73,8.97" target="#b14">[15]</ref>  <ref type="bibr" coords="1,402.39,221.87,13.36,8.97" target="#b28">[29]</ref>, which all share the vision of bridging journalism and technology. The progress made in NLP has been gradually integrated into the journalistic field <ref type="bibr" coords="1,496.93,243.79,10.42,8.97" target="#b4">[5]</ref>[8] <ref type="bibr" coords="1,517.78,243.79,13.90,8.97" target="#b53">[54]</ref>. More specifically, machine learning models based on transformers have been integrated in the media sector in different tasks <ref type="bibr" coords="1,514.31,265.71,14.76,8.97" target="#b40">[41]</ref> such as the creation of headlines with generative languages models <ref type="bibr" coords="1,542.33,276.67,13.49,8.97" target="#b16">[17]</ref>, summarization of news articles <ref type="bibr" coords="1,433.37,287.63,13.90,8.97" target="#b27">[28]</ref> <ref type="bibr" coords="1,447.27,287.63,13.90,8.97" target="#b26">[27]</ref>, false news detection <ref type="bibr" coords="1,542.58,287.63,13.29,8.97" target="#b48">[49]</ref>, and topic modeling and sentiment analysis <ref type="bibr" coords="1,469.75,298.59,13.22,8.97" target="#b24">[25]</ref>. The development of large language models such as GPT-3 <ref type="bibr" coords="1,452.85,309.54,9.27,8.97" target="#b8">[9]</ref>, BLOOM <ref type="bibr" coords="1,498.85,309.54,14.59,8.97" target="#b50">[51]</ref> or ChatGPT show a clear trend towards human-machine interaction becoming easier and more intuitive, opening up a wide range of research possibilities. At the same time, the use of these models is also associated with a lack of transparency regarding how these models work, but efforts are being made to bring some transparency to these models, and to analyze use cases where they can be useful and where they cannot <ref type="bibr" coords="1,389.20,386.26,13.44,8.97" target="#b34">[35]</ref>. Based on the premises that these models open up a wide range of research directions <ref type="bibr" coords="1,473.22,397.22,9.27,8.97" target="#b6">[7]</ref>, and that at the same time (and needless to say) they are not the solution to all problems, we are interested in identifying use cases and tasks where they can be potentially useful, while acknowledging and systematically documenting their limitations <ref type="bibr" coords="1,432.68,441.05,13.49,8.97" target="#b55">[56]</ref>. More specifically, the aim of this work is to analyze the performance of GPT-3.5 for a specific use case, namely the analysis of frames in news, from an empirical point of view, with the objective of shedding light on a potential use of generative models in journalistic tasks.</p><p>Frame analysis is a concept from journalism, which consists of studying the way in which news stories are presented on an issue, and what aspects are emphasized: Is a merely informative vision given in an article? Or is it intended to leave a moral lesson? Is a news article being presented from an economic point of view? Or from a more human, emotional angle? The examples above correspond to different frames with which an article can be written.</p><p>The concept of news framing has been studied in computing as a step beyond topic modeling and sentiment analysis, and for this purpose, in recent years, pre-trained language models have been used for fine-tuning the classification process of these frames <ref type="bibr" coords="1,543.50,605.44,14.70,8.97" target="#b59">[60]</ref> [10], but the emergence of generative models opens the possibility of doing prompt-engineering of these classification tasks, instead of the fine-tuning approach investigated so far.</p><p>Our work aims to address this research gap by posing the following research questions:</p><p>RQ1: What are the main frames in the news headlines about the anti-vaccine movement, as reported in newspapers across 5 European countries? RQ2: Can prompt engineering be used for classification of headlines according to frames? By addressing the above research questions, our work makes the following contributions: Contribution 1. We implemented a process to do human annotation of the main frame of 1786 headlines of articles about the Covid-19 no-vax movement, as reported in 19 newspapers from 5 European countries (France, Italy, Spain, Switzerland and United Kingdom.) At the headline level, we found that the predominant frame was human interest, where this frame corresponds to a personification of an event, either through a statement by a person, or the explanation of a specific event that happened to a person. Furthermore, we found a large number of headlines annotated as containing no frame, as they simply present information without entering into evaluations. We also found that for all the countries involved, the distribution of frame types was very similar, i.e., human interest and no frame are the two predominant frames. Finally, the generated annotations allowed to subsequently study the performance of a large language model. Contribution 2. We studied the performance of GPT-3.5 on the task of frame classification of headlines. In addition to using the fine-tuning approach from previous literature, we propose an alternative approach for frame classification that requires no labeled data for training, namely prompt-engineering using GPT-3.5. The results show that fine-tuning with GPT-3.5 produces 72% accuracy (slightly higher than other smaller models), and that the promptengineering approach results in lower performance (49% accuracy.) Our analysis also shows that the subjectivity of the human labeling task has an effect on the obtained accufracy.</p><p>The paper is organized as follows. In Section 2, we discuss related work. In Section 3, we describe the news dataset. In Section 4, we describe the methodology for both human labeling and machine classification of news frames. We present and discuss results for RQ1 and RQ2 in Sections 5 and 6, respectively. Finally, we provide conclusions in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Framing has been a concept widely studied in journalism, with a definition that is rooted in the study of this domain <ref type="bibr" coords="2,239.72,514.32,13.34,8.97" target="#b22">[23]</ref>: "To frame is to select some aspects of a perceived reality and make them more salient in a communicating text, in such a way as to promote a particular problem definition, causal interpretation, moral evaluation, and/or treatment recommendation for the item described. "</p><p>For frame recognition, there are two main approaches: the inductive approach <ref type="bibr" coords="2,105.45,580.08,13.30,8.97" target="#b15">[16]</ref>, where one can extract the frames after reading the article, and the deductive approach <ref type="bibr" coords="2,202.43,591.03,13.49,8.97" target="#b37">[38]</ref>, where a predefined list of frames exists and the goal is to interpret if any of them appears in the article. In the deductive case, there are generic frames and subject-specific frames, and the way to detect them typically involves reading and identifying one frame at a time, or through answers to yes/no questions that represent the frames. Semetko et al. <ref type="bibr" coords="2,64.27,656.79,14.60,8.97" target="#b51">[52]</ref> used 5 types of generic frames (attribution of responsibility, human interest, conflict, morality, and economic consequences) based on previous literature, and they defined a list of 20 yes/no questions to detect frames in articles. For instance, the questions about morality are the following: "Does the story contain any moral message? Does the story make reference to morality, God, and other religious tenets? Does the story offer specific social prescriptions about how to behave?", and so on for each of the frame types. This categorization of frames has been used in various topics such as climate change <ref type="bibr" coords="2,376.83,130.76,14.85,8.97" target="#b17">[18]</ref> [19], vaccine hesitance <ref type="bibr" coords="2,481.78,130.76,13.49,8.97" target="#b12">[13]</ref>, or immigration <ref type="bibr" coords="2,317.96,141.72,13.36,8.97" target="#b33">[34]</ref>.</p><p>We now compare the two approaches on a common topic, such as Covid-19. Ebrahim et al. <ref type="bibr" coords="2,421.95,163.64,14.85,8.97" target="#b20">[21]</ref> followed an inductive approach in which the frames were not predefined but emerged from the text (e.g., deadly spread, stay home, what if, the cost of Covid-19) using headlines as the unit of analysis. In contrast, the deductive approach has studied very different labels. El-Behary et al. <ref type="bibr" coords="2,543.35,207.47,14.85,8.97" target="#b21">[22]</ref> followed the method of yes/no questions, but in addition to the 5 generic frames presented before, they also used blame frame and fear frame. Adiprasetio et al. <ref type="bibr" coords="2,444.28,240.35,10.68,8.97" target="#b0">[1]</ref> and Rodelo <ref type="bibr" coords="2,502.25,240.35,14.85,8.97" target="#b49">[50]</ref> used the 5 generic frames with yes/no questions, while Catalán-Matamoros et al. <ref type="bibr" coords="2,328.93,262.27,14.85,8.97" target="#b13">[14]</ref> used the 5 frames and read the headline and subheadline to decide the main frame. Table <ref type="table" coords="2,442.93,273.23,4.25,8.97" target="#tab_0">1</ref> summarizes some of the the existing approaches. This previous work showed how frame labels can be different, and also that frame analysis has been done at both headline and article levels. These two approaches (inductive and deductive) that originated in journalism have since been replicated in the computing literature.</p><p>We decided to follow the deductive approach because a predefined list of frames allows to compare among topics, countries, previous literature, and also because they represent a fixed list of labels for machine classification models. Furthermore, the inductive approach tends to be more specific to a topic, and from the computing viewpoint, past work has tried to justify topic modeling as a technique to extract frames from articles.</p><p>Ylä-Antitila et al. <ref type="bibr" coords="2,394.18,415.69,14.85,8.97" target="#b59">[60]</ref> proposed topic modeling as a frame extraction technique. They argued that topics can be interpreted as frames if three requirements are met: frames are operationalized as connections between concepts; subject-specific data is selected; and topics are adequately validated as frames, for which they suggested a practical procedure. This approach was based on the choice of a specific topic (e.g., climate change) and the use of Latent Dirichlet Allocation (LDA) as a technique to extract a number of subtopics. In a second phase, a qualitative study of the top 10 words of each subtopic was performed, and the different subtopics were eliminated or grouped, reducing the number and establishing a tentative description. In a third phase, the top 10 articles belonging to that frame/topic were taken, and if the description of the topic fitted at least 8 of the 10 articles, that topic/frame remained. The frames found in this article were: green growth, emission cuts, negotiations and treaties, environmental risk, cost of carbon emissions, Chinese emissions, economics of energy production, climate change, environmental activism, North-South burden sharing, state leaders negotiating, and citizen participation.</p><p>From Entman's definition of frame <ref type="bibr" coords="2,454.94,623.91,13.23,8.97" target="#b22">[23]</ref>, it seems that the deductive approach is more refined than the inductive approach (which seems to resemble the detection of sub-themes.) For example, with regard to climate change, there are stories on how people have been affected by climate change from an emotional point of view, thus personalizing the problem. In this case, we could categorize the corresponding frame as human interest, as the writer of the article is selecting "some aspects of a perceived reality and make them more salient". The language subtleties with which news articles are presented cannot be captured with basic topic modeling.</p><p>Isoaho et al. <ref type="bibr" coords="3,111.92,108.84,13.40,8.97" target="#b29">[30]</ref> held the position that while the benefits of scale and scope in topic modeling were clear, there were also a number of problems, namely that topic outputs do not correspond to the methodological definition of frames, and thus topic modeling remained an incomplete method for frame analysis. Topic modeling, in the practice of journalistic research, is a useful technique to deal with the large datasets that are available, yet is often not enough to do more thorough analyses <ref type="bibr" coords="3,152.69,185.55,13.23,8.97" target="#b30">[31]</ref>. In our work, we clearly notice that frame analysis is not topic modeling. For example, two documents could be about the same topic, say Covid-19 vaccination, but one article could emphasize the number of deaths after vaccination, while the other emphasized the role of the vaccine as a solution to the epidemic.</p><p>We also consider that the larger the number of possible frame types, the more likely it is to end up doing topic modeling instead of frame analysis. Using a deductive approach, Dallas et al. <ref type="bibr" coords="3,251.74,273.23,14.59,8.97" target="#b11">[12]</ref> created a dataset with articles about polemic topics such as immigration, same sex marriage, or smoking, and they defined 15 types of frames: "economic, capacity and resources, morality, fairness and equality, legality, constitutionality and jurisprudence, policy prescription and evaluation, crime and punishment, security and defense, health and safety, quality of life, cultural identity, political, external regulation and reputation, other". In this case, they authors did not use a list of questions. Instead, for each article, annotators were asked to identify any of the 15 framing dimensions present in the article and to label text blurbs that cued them (based on the definitions of each of the frame dimensions) and decide the main frame of each article. In our case, we followed the idea of detecting the main frame by reading the text instead of answering questions, but instead of using the 15 frames proposed in <ref type="bibr" coords="3,169.93,426.65,14.59,8.97" target="#b11">[12]</ref> , we used the 5 generic frames proposed in <ref type="bibr" coords="3,99.35,437.61,13.36,8.97" target="#b51">[52]</ref>.</p><p>A final decision in our work was the type of text to analyze, whether headlines or whole article. For this decision, the chosen classification method was also going to be important. For example, Khanehzar et al. <ref type="bibr" coords="3,114.91,481.44,14.68,8.97" target="#b32">[33]</ref> used traditional approaches such as SVMs as baseline, and demonstrated the improvement in frame classification with the use of pre-trained languages models such as BERT, RoBERTa and XLNet, following a fine-tuning approach, setting as input text a maximum of 256 tokens (although the maximum number of input tokens in these models is 512 tokens.) Liu et al. <ref type="bibr" coords="3,53.80,547.20,14.60,8.97" target="#b36">[37]</ref> classified news headlines about the gun problem in the United States, arguing for the choice of headlines as a unit of analysis based on previous journalism literature <ref type="bibr" coords="3,204.19,569.12,9.52,8.97" target="#b5">[6]</ref>, <ref type="bibr" coords="3,219.45,569.12,13.49,8.97" target="#b43">[44]</ref>, that advocated for the importance and influence of headlines on readers and the subsequent perception of articles. From a computational viewpoint, using headlines is also an advantage, since you avoid the 512 token limitation in BERT-based models. Therefore, we decided to work with headlines about a controversial issue, namely the Covid-19 no-vax movement.</p><p>Continuing with the question of the methods used for classification, much work has been developed in prompt engineering, especially since the release of GPT-3. Liu et al. <ref type="bibr" coords="3,218.46,667.75,13.06,8.97" target="#b35">[36]</ref> presented a good overview of the work done on this new NLP paradigm, not only explaining the concept of prompt engineering, but also the different strategies that can be followed both in the design of prompts, [12] 15 generic frames: "Economic", "Capacity and resources", "Morality", "Fairness and equality", "Legality, constitutionality and jurisprudence", "Policy prescription and evaluation", "Crime and punishment", "Security and defense", "Health and safety", "Quality of life", "Cultural identity", "Public opinion", "Political", "External regulation and reputation", "Other".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>To label frames of full articles</head><p>Reading the full article, the annotator defines the main frame 20000 articles <ref type="bibr" coords="3,323.62,187.33,8.51,5.23" target="#b32">[33]</ref>  131 headlines + subheadlines the potential applications, and the challenges to face when using this approach. Prompt engineering applications include knowledge probing <ref type="bibr" coords="3,347.84,409.85,13.23,8.97" target="#b45">[46]</ref>, information extraction <ref type="bibr" coords="3,449.09,409.85,13.22,8.97" target="#b52">[53]</ref>, NLP reasoning <ref type="bibr" coords="3,521.95,409.85,13.22,8.97" target="#b56">[57]</ref>, question answering <ref type="bibr" coords="3,373.09,420.81,13.22,8.97" target="#b31">[32]</ref>, text generation <ref type="bibr" coords="3,447.01,420.81,13.22,8.97" target="#b19">[20]</ref>, multi-modal learning <ref type="bibr" coords="3,542.66,420.81,13.22,8.97" target="#b57">[58]</ref>, and text classification <ref type="bibr" coords="3,397.35,431.76,13.22,8.97" target="#b23">[24]</ref>, the latter being the prompt-engineering use case in our work. Puri et al. <ref type="bibr" coords="3,437.48,442.72,13.40,8.97" target="#b44">[45]</ref> presented a very interesting idea that we apply to our classification task. This consists of providing the language model with natural language descriptions of classification tasks as input, and training it to generate the correct answer in natural language via a language modeling objective. It is a zero-shot learning approach, in which no examples are used to explain the task to the model. Radford et al. <ref type="bibr" coords="3,475.80,508.48,14.59,8.97" target="#b47">[48]</ref> demonstrated that language models can learn tasks without any explicit supervision. We have followed this approach to find an alternative way to do frame analysis.</p><p>As mentioned before, the emergence of giant models like GPT-3, BLOOM, and ChatGPT are a very active research topic. To the best of our knowledge, on one hand our work extends the computational analysis of news related to the covid-19 no-vax movement, which illustrates the influence of the press on the ways societies think about relevant issues <ref type="bibr" coords="3,398.93,607.11,13.49,8.97" target="#b39">[40]</ref>, <ref type="bibr" coords="3,418.22,607.11,13.49,8.97" target="#b58">[59]</ref>, and on the other hand it adds to the literature of human-machine interaction, regarding the design of GPT-3 prompts for classification tasks <ref type="bibr" coords="3,468.70,629.03,13.36,8.97" target="#b38">[39]</ref>, <ref type="bibr" coords="3,487.64,629.03,9.39,8.97" target="#b1">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DATA: EUROPEAN COVID-19 NEWS DATASET</head><p>We used part of the European Covid-19 News dataset collected in our recent work <ref type="bibr" coords="3,378.73,689.66,9.34,8.97" target="#b2">[3]</ref>. This dataset contains 51320 articles on Covid-19 vaccination from 19 newspapers from 5 different countries: Italy, France, Spain, Switzerland and UK. The articles cover a time period of 22 months, from January 2020 to October 2021. All content was translated into English to be able to work in a common language. The dataset was used for various analyses, such as name entity recognition, sentiment analysis, and subtopic modeling, to understand how Covid-19 vaccination was reported in Europe through the print media (in digital format.) The subtopic modeling analysis revealed a subsample of articles on the no-vax movement, which is the one we have used in this paper. We took the headlines of the articles associated with the no-vax movement, selecting all articles containing any of the keywords in Table <ref type="table" coords="4,201.25,196.51,4.09,8.97">2</ref> in the headline or in the main text. This corresponds to a total of 1786 headlines.</p><p>Table <ref type="table" coords="4,97.14,231.53,3.45,7.70">2</ref>: Keywords used to identify no-vax articles Keywords NO VAX TOPIC "anti-vaxxers", "anti-vaccine", "anti-vaxx", "anti-corona", "no-vax", "no vax", "anti-vaccin"</p><p>In Table <ref type="table" coords="4,96.39,288.48,3.13,8.97" target="#tab_2">3</ref>, we show the number of headlines per country and newspaper. France is the country with the most no-vax articles in the corpus, with 523 articles, followed by Italy with 508. However, note that there are 6 newspapers from France, while only 2 from Italy. Corriere della Sera is the newspaper that dealt most frequently with the subject (429 articles), while The Telegraph is the second one (206 articles). The total number of articles normalized by the number of newspapers per country is also shown in the last column of the Table . Using these normalized values, the ranking is Italy, UK, France, Switzerland, and Spain. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">METHODOLOGY 4.1 Human labeling of news frames</head><p>To carry out the labeling of the frames in our corpus of headlines, we first designed a codebook, which contained the definitions of each of the frame types and a couple of examples of each type, as well as a definition of the corpus subject matter and definitions of the concept of frame analysis, so that the annotators could understand the task to be performed. The codebook follows the proposed by <ref type="bibr" coords="4,317.96,86.92,14.85,8.97" target="#b51">[52]</ref> with 5 generic frames (attribution of responsibility, human interest, conflict, morality, and economic consequences) plus one additional 'no-frame' category. Two researchers were engaged to annotate a sample of the collected newspaper articles following a three-phase training procedure.</p><p>In the first phase, annotators had to read the codebook and get familiar with the task. In the second phase, they were asked to identify the main frame in the same subset of 50 headlines. At the end of the second phase, the intercoder reliability (ICR) was 0.58 between the 2 annotators. We analyzed those cases where there were discrepancies, and observed that in some cases, there was not a unique main frame, because both annotators had valid arguments to select one of the frames. In other cases, the discrepancies were due to slight misunderstanding of the definitions. In the third phase, the annotators coded again 50 headlines, and the ICR increased to was 0.66. We realized that the possibility of having two frames remained. They discussed the cases in which they had disagreed, and if the other person's arguments were considered valid, it could be said that there were two frames. After this three-phase training procedure, annotators were ready to annotate the dataset independently. We divided the dataset into two equal parts, and each person annotated 893 headlines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Fine-tuning GPT-3.5 and BERT-based models</head><p>With the annotated dataset, we investigated two NLP approaches: the first one involves fine-tuning a pre-trained model; the second one is prompt engineering. Pre-trained language models have been In the first approach, a model with a fixed architecture is pretrained as a language model (LM), predicting the likelihood of the observed textual data. This can be done due to the availability of large, raw text data needed to train LMs. This learning process can produce general purpose features of the modeled language. The learning process produces robust, general-purpose features of the language being modeled. The above pre-trained LM is then adapted to different downstream tasks, by introducing additional parameters and adjusting them using task-specific objective functions. In this approach, the focus was primarily on goal engineering, designing the training targets used in both the pre-training and the fine-tuning stages <ref type="bibr" coords="4,342.61,700.62,13.36,8.97" target="#b35">[36]</ref>.</p><p>We present an example to illustrate the idea. Imagine that the task is sentiment analysis, and we have a dataset with sentences and their associated sentiment, and a pre-trained model, which is a saved neural network trained with a much larger dataset. For that pre-trained model to address the target task, we unfreeze a few of the top layers of the saved model base and jointly train both the newly-added classifier layers and the last layers of the base model. This allows to "fine-tune" the higher-order feature representations in the base model to make them more relevant for the sentiment analysis task. In this way, instead of having to obtain a very large dataset with target labels to train a model, we can reuse the pretrained model and use a much smaller train dataset. We use a part of our dataset as examples for the model to learn the task, while the other part of the dataset is used to evaluate model performance.</p><p>Previous works related to frame classification in the computing literature have used fine-tuning, BERT-based models. In our work, we have done the same as a baseline, but we aimed to go one step further and also produce results using fine-tuning of GPT-3.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Prompt-engineering with GPT-3.5</head><p>Model fine-tuning has been widely used, but with the emergence of generative models such as GPT-3, another way to approach classification tasks has appeared. The idea is to use the pre-trained model directly and convert the task to be performed into a format as close as possible to the tasks for which it has been pre-trained. That is, if the model has been pre-trained from next word prediction as in the case of GPT-3, classification can be done by defining a prompt, where the input to the model is an incomplete sentence, and the model must complete it with a word or several words, just as it has been trained. This avoids having to use part of the already labeled dataset to teach the task to be performed to the model, and a previous labeling is not needed <ref type="bibr" coords="5,176.28,437.61,13.36,8.97" target="#b35">[36]</ref>.</p><p>In this approach, instead of adapting pre-trained LMs to downstream tasks via objective engineering, downstream tasks are reformulated to look more like those solved during the original LM training with the help of a textual prompt. For example, when recognizing the emotion of a social media post, "I missed the bus today. ", we may continue with a prompt "I felt so _", and ask the LM to fill the blank with an emotion-bearing word. Or if we choose the prompt "English: I missed the bus today. French: _"), an LM may be able to fill in the blank with a French translation. In this way, by selecting the appropriate prompts, we can influence the model behavior so that the pre-trained LM itself can be used to predict the desired output, even without any additional task-specific training <ref type="bibr" coords="5,53.80,580.08,13.36,8.97" target="#b35">[36]</ref>.</p><p>We use this emerging NLP approach to classify frames at headline level. We are not aware of previous uses of this strategy to classify frames as we propose here. The idea is the following. Prompt engineering consists of giving a prompt to the model, and understands that prompt as an incomplete sentence. To do prompt engineering with our dataset, we needed to define an appropriate prompt that would produce the headline frames as output. We defined several experiments with the Playground of GPT-3, in order to find the best prompt for our task. In our initial experiments, we followed existing approaches in prompt engineering to do sentiment analysis, where the individual answer was an adjective, and this adjective was matched with a sentiment. In a similar fashion, we decided to build a thesaurus of adjectives that define each of the frames. For instance, the human interest frame could be 'interesting', 'emotional', 'personal', 'human'. The conflict frame could be: 'conflictive', 'bellicose', 'troublesome', 'rowdy', 'quarrelsome', 'troublemaker', 'agitator', etc. After the list of adjectives was defined, we needed to define the prompt in order to get, as an answer, one of the adjectives in our thesaurus to match them with the frame. We used the GPT-3 playground using the headline as input and asking for the frame as output, but the strategy did not work. In our final experiment, instead of giving the headline as input, we gave the definitions of each type of frame plus the headline, and we asked the model to choose between the different types of frames as output. In this way, the output of the model was directly one of the frames, and we avoided the step of matching adjectives with frames. An example is shown in Figure <ref type="figure" coords="5,462.91,251.31,3.07,8.97" target="#fig_1">2</ref>. After testing with the GPT-3 playground and varying different hyper-parameters to assess performance, we set the temperature to 0, since the higher the temperature the more random the response. Furthermore, the Top-p parameter was set to 1, as it would likely get a set of the most likely words for the model to choose from. The maximum number of tokens was set to 2; in this way, the model is asked to choose between one of the responses. As a model, we used the one with the best performance at the time of experimental design, which was TEXT-DAVINCI-003, recognized as GPT 3.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RESULTS: HUMAN LABELING OF FRAMES IN NO-VAX NEWS HEADLINES (RQ1)</head><p>In this section, we present and discuss the results of the analysis related to our first RQ. Figure <ref type="figure" coords="5,352.59,669.95,4.09,8.97">3</ref> shows the distribution of frames per country at headline level, with human interest and no-frame being the predominant ones. Attribution of responsibility is the third one except in Switzerland, where the corresponding frame is conflict. Finally, morality and economic are the least represented in the dataset for every country.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 3: Non-normalized distribution of frames per country</head><p>The monthly distribution of frames aggregated for all countries is shown in Fig. <ref type="figure" coords="6,110.96,470.49,3.01,8.97" target="#fig_2">4</ref>. We can see two big peaks, the first one in January 2021 and the second one in August 2021. In all countries, the vaccination process started at the end of December 2020, so it makes sense that the no-vax movement started to be more predominant in the news in January 2021. Human interest is the most predominant frame. Manual inspection shows that this is because the headlines are about personal cases of people who are pro-or anti-vaccine. Attribution of responsibility is also present. Manual inspection indicates that local politicians and health authorities had to make decisions about who could be vaccinated at the beginning of the process. The second peak at the end of summer 2021 coincided with the health pass (also called Covid passport in some countries), and we can observe a peak in the curve corresponding to the conflict frame, reflecting the demonstrations against the measure of mandatory health passes taken by country governments.</p><p>In Figure <ref type="figure" coords="6,97.45,634.87,3.01,8.97" target="#fig_3">5</ref>, we compare the sentiment per frame and per country, to understand if there were any major differences. The sentiment analysis labels were obtained using BERT-sent from the Hugging Face package <ref type="bibr" coords="6,105.02,667.75,13.45,8.97" target="#b46">[47]</ref>, used in our previous work (please refer to our original analysis in <ref type="bibr" coords="6,127.07,678.71,10.67,8.97" target="#b2">[3]</ref> for details.) We normalized the results between 0 and 1 to compare frames between countries. We see that the sentiment is predominantly neutral (in blue). Examining in more  Regarding the results of the annotation process, the fact that the distribution of the 6 frame types is relatively similar between countries suggests that the anti-vaccine movement issue was treated in a similar way in these countries. The fact that human interest is the most dominant frame indicates that this issue was treated from a more human and emotional approach, with headlines about personal experiences, celebrities giving their opinion about vaccination, and politicians defending vaccine policies. Moreover, the reason for many headlines being classified as no-frame is partly due to how data was selected. We chose articles that contained words related to no-vax, either in the headline or in the article. This resulted in many headlines not containing anything specific related to no-vax, while the no-vax content was actually included in the main text of the corresponding articles.</p><p>It is worth mentioning that prior to obtaining the results, we had expected that attribution of responsibility would be among the most prominent frames, since governments took many measures such as mandatory health pass requirements to access certain sites; we had also expected that the conflict frame would be prominent, since there were many demonstrations in Europe. In reality, however, these frames categories were not reflected as frequently at the headline level.</p><p>Regarding the analysis at the temporal level, it is clear that certain events were captured by the press, such as the start of vaccination or the mandatory vaccination passport.</p><p>Finally, the sentiment analysis of the different frames shows that the predominant tone in all of them is neutral or negative, with very similar trends between countries. This association between sentiment analysis and frames has been discussed in previous literature <ref type="bibr" coords="7,53.80,404.73,14.72,8.97" target="#b10">[11]</ref>  <ref type="bibr" coords="7,70.76,404.73,13.36,8.97" target="#b42">[43]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RESULTS: GPT-3.5 FOR FRAME CLASSIFICATION OF HEADLINES (RQ2)</head><p>Here, we present and discuss the results related to our second RQ.</p><p>6.1 Fine-tuning GPT-3.5</p><p>Table <ref type="table" coords="7,76.50,494.17,4.25,8.97" target="#tab_3">4</ref> shows the results of the 6-class classification task using 5-cross validation. Three models were used: GPT-3.5 and two BERTbased models. We observe that, on average, GPT-3.5 performs better than the BERT-based models. This is somehow expected as GPT-3.5 is a much larger model. Overall, in the case of fine-tuning, the best performance for the six-class frame classification task is 72% accuracy, which is promising, with an improvement over previous models based on BERT. Yet, it should be noted that the performance differences are modest (2% improvement between GPT-3.5 and RoBERTa). On the other hand, BERT is open-source, while GPT-3 has an economic cost as the use of the model is not free, which monetarily limits the number of experiments that can be performed with it, as well as the different configurations one can explore to improve performance. This is important because much of the improvement in performance requires empirical explorations of model parameters More specifically, the cost of an experiment for each of the folds has a cost of 4 dollars (at the time of writing this paper.) This represents a limitation in practice.</p><p>Furthermore, GPT-3 has a significant carbon footprint. Similarly, for prompt engineering (discussed in the next subsection), choosing the right prompt (i.e., the words that best define the task so that the model is able to perform adequately) is also based on trial and error. This also has an impact on carbon footprint. In connection with this topic, Strubell et al. <ref type="bibr" coords="7,406.28,240.35,13.26,8.97" target="#b54">[55]</ref> argue that improvements in the accuracy of models depend on the availability of large computational resources, which involve large economic and environmental costs. A criticism has been made as 'the rich get richer', in the sense that not all research groups have sufficient infrastructure resources and access to funding needed to use these models and improve their performance. Also in relation to this analysis, the work of Bender et al. <ref type="bibr" coords="7,337.75,317.06,10.57,8.97" target="#b3">[4]</ref> evaluates the costs and risks of the use of large language models, stating that researchers should be aware of the impact that these models have on the environment, and assess whether the benefits outweigh the risks. The work in <ref type="bibr" coords="7,465.31,349.94,10.42,8.97" target="#b3">[4]</ref> provides a very telling example, where people living in the Maldives or Sudan are affected by floods and pay the environmental price of training English LLMs, when similar models have not been produced for languages like Dhivehi or Sudanese Arab. In short, there is a need to establish ways to use this technological development responsibly, and it all starts with being aware of the risks it presents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Prompt-engineering with GPT-3.5</head><p>For each headline, we got the frame that the model considered the most likely, and we compared these GPT-3.5 inferences with the frames labeled by the annotators. The agreement between model and annotator was of 49%. Analyzing the results, and specifically looking at the cases where the annotator and GPT-3.5 disagreed, we discovered that according to the frame definitions, the model in some cases proposed a frame that indeed made sense. This observation, together with our previous experience in the annotation process, where headlines could have more than one valid frame, led us to design a second post-hoc experiment. We took all the headlines where each of the two annotators had disagreed with GPT-3.5, and we asked the annotators to state whether they would agree (or not) with each GPT-inferred label for a given headline. It is important to emphasize that the annotators did not know the origin of that label, i.e., they did not know if it was the label they had originally assigned, or if it was a random one. In this way, we could quantify how GPT-3.5 worked according to valid arguments provided by the annotators. In this post-hoc experiment, the model agreed in 76% of cases with the annotators.</p><p>Looking at the results of the classification models, the 49% accuracy of the prompt-engineering approach can be considered low, yet we consider that it is a valid avenue for further investigation, as in the second post-hoc analysis, we found that the model agrees with human annotators in 76% of the cases. Clearly, framing involves aspects of subjectivity <ref type="bibr" coords="8,162.75,97.88,13.40,8.97" target="#b41">[42]</ref>. Much of what we do as people has a subjective component, influenced by how we feel or how we express opinions.</p><p>News reading is never fully objective, and the annotators engaged in the frame classification task, influenced by their personal state of mind, experience, and culture, may perceive information differently. Monarch affirms that "for simple tasks, like binary labels on objective tasks, the statistics are fairly straightforward to decide which is the 'correct' label when different annotators disagree. But for subjective tasks, or even objective tasks with continuous data, there are no simple heuristics for deciding what the correct label should be" <ref type="bibr" coords="8,94.10,218.43,13.36,8.97" target="#b41">[42]</ref>.</p><p>Subjectivity is involved in both the generation and perception of information: the assumption that there is only one frame is complicated by the point of view of the reader. In the case of news, the information sender (the journalist) has an intention, but the receiver (the reader) plays a role and is influenced by it. In psychology, this is known as the lens model of interpersonal communication, where the sender has certain objectives, but the receiver can interpret or re-interpret what the sender wants to say, with more or less accuracy <ref type="bibr" coords="8,88.46,317.06,13.36,8.97" target="#b25">[26]</ref>.</p><p>Following this discussion on subjectivity, the question arose as to what would happen if, instead of headlines, we used the complete article as a source of analysis. We wondered if longer text could make the frame labeling task clearer than when using headlines. Yet another possible hypothesis is that having to read longer texts could lead to the same subject being presented from different angles. Please recall that in the existing literature discussed in Section 2, both headlines and full articles have been used from frame analysis (see Table <ref type="table" coords="8,91.96,415.69,2.94,8.97" target="#tab_0">1</ref>.) This remains as an issue for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSIONS</head><p>In this paper, we first presented an analysis of human-generated news frames on the covid-19 no-vax movement in Europe, and then studied different approaches using large language models for automatic inference of frames. We conclude by answering the two research questions we posed: RQ1: What are the main frames in the news headlines about the covid-19 anti-vaccine movement in 5 European countries? After annotating the headlines, we found that of the 1786 headlines, the predominant frame is human interest (45.3% of cases), which presents a news item with an emotional angle, putting a face to a problem or situation. We also found that a substantial proportion of headlines were annotated as not presenting any frame (40.2% of cases). Finally, the other frame types are found more infrequently.</p><p>RQ2: Can prompt engineering be used for classification of headlines according to frames? We first used fine-tuning of a number of language models, and found that GPT-3.5 produced classification accuracy of 72% on a six-frame classification task. This represented a modest 2% improvement over BERT-based models, at a significantly larger environmental cost. We then presented a new way of classifying frames using prompts. At the headline level, inferences made with GPT-3.5 reached 49% of agreement with human-generated frame labels. In many cases, the GPT-3.5 model inferred frame types that were considered as valid choices by human annotators, and in an post-doc experiment, the human-machine agreement reached 76%. These results have opened several new directions for future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,362.69,519.22,150.77,7.70;4,317.96,414.24,240.25,90.98"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Pre-train, fine-tune, prompt</figDesc><graphic coords="4,317.96,414.24,240.25,90.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,325.69,371.17,224.78,7.70;5,317.96,274.61,240.25,82.56"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: GPT-3.5 for frame inference: input and output</figDesc><graphic coords="5,317.96,274.61,240.25,82.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,320.35,329.43,235.47,7.70;6,317.96,83.68,240.25,231.75"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Non-normalized monthly distribution of frames.</figDesc><graphic coords="6,317.96,83.68,240.25,231.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="6,323.21,698.43,229.75,7.70;6,317.96,555.87,240.24,128.57"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Sentiment of headline by frame and by country</figDesc><graphic coords="6,317.96,555.87,240.24,128.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,317.66,85.73,240.55,35.30"><head>Table 1 :</head><label>1</label><figDesc>Summary of deductive approaches for frame analysis</figDesc><table coords="3,323.62,110.43,229.62,10.60"><row><cell>Ref Frames</cell><cell>Goal</cell><cell>Technique</cell><cell>Number of</cell></row><row><cell></cell><cell></cell><cell></cell><cell>samples</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,59.09,411.17,229.66,176.37"><head>Table 3 :</head><label>3</label><figDesc>Number of headlines by newspaper and country</figDesc><table coords="4,59.09,436.42,229.66,151.12"><row><cell>COUNTRY</cell><cell>NEWSPAPER</cell><cell>HEADLINES</cell><cell>TOTAL (NORM. TOTAL)</cell></row><row><cell>FRANCE</cell><cell>La Croix</cell><cell>94</cell><cell>523 (87.1)</cell></row><row><cell></cell><cell>Le Monde</cell><cell>125</cell><cell></cell></row><row><cell></cell><cell>Les Echos</cell><cell>49</cell><cell></cell></row><row><cell></cell><cell>Liberation</cell><cell>97</cell><cell></cell></row><row><cell></cell><cell>Lyon Capitale</cell><cell>8</cell><cell></cell></row><row><cell></cell><cell>Ouest France</cell><cell>150</cell><cell></cell></row><row><cell>ITALY</cell><cell>Corriere della Sera</cell><cell>429</cell><cell>508 (254.0)</cell></row><row><cell></cell><cell>Il Sole 24 Ore</cell><cell>79</cell><cell></cell></row><row><cell>SPAIN</cell><cell>20 minutos</cell><cell>27</cell><cell>303 (50.5)</cell></row><row><cell></cell><cell>ABC</cell><cell>50</cell><cell></cell></row><row><cell></cell><cell>El Diario</cell><cell>32</cell><cell></cell></row><row><cell></cell><cell>El Mundo</cell><cell>77</cell><cell></cell></row><row><cell></cell><cell>El Español</cell><cell>22</cell><cell></cell></row><row><cell></cell><cell>La Vanguardia</cell><cell>95</cell><cell></cell></row><row><cell>SWITZERLAND</cell><cell>24 heures</cell><cell>97</cell><cell>230 (76.6)</cell></row><row><cell></cell><cell>La Liberté</cell><cell>22</cell><cell></cell></row><row><cell></cell><cell>Le Temps</cell><cell>111</cell><cell></cell></row><row><cell>UNITED KINGDOM</cell><cell>The Irish News</cell><cell>16</cell><cell>222 (111.0)</cell></row><row><cell></cell><cell>The Telegraph</cell><cell>206</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>1786</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,53.50,625.45,242.15,78.10"><head>Table 4</head><label>4</label><figDesc></figDesc><table coords="7,53.80,625.45,241.85,78.10"><row><cell cols="7">: Classification results for six-class frame classifica-</cell></row><row><cell cols="4">tion and 5-fold cross validation</cell><cell></cell><cell></cell><cell></cell></row><row><cell>ACCURACY</cell><cell>0</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>AVERAGE</cell></row><row><cell>BERT</cell><cell>0.68</cell><cell>0.69</cell><cell>0.72</cell><cell>0.64</cell><cell>0.70</cell><cell>0.67</cell></row><row><cell>RoBERTa</cell><cell>0.70</cell><cell>0.72</cell><cell>0.72</cell><cell>0.67</cell><cell>0.71</cell><cell>0.70</cell></row><row><cell>GPT3</cell><cell>0.75</cell><cell>0.70</cell><cell>0.72</cell><cell>0.71</cell><cell>0.71</cell><cell>0.72</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="5,320.88,702.12,119.78,6.97"><p>https://beta.openai.com/docs/introduction</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>This work was supported by the <rs type="projectName">AI4Media</rs> project, funded by the <rs type="funder">European Commission</rs> (Grant <rs type="grantNumber">951911</rs>) under the <rs type="grantNumber">H2020 Programme ICT-48-2020</rs>. We also thank the newspapers for sharing their online articles. Finally, we thank our colleagues <rs type="person">Haeeun Kim</rs> and <rs type="person">Emma Bouton-Bessac</rs> for their support with annotations, and <rs type="person">Victor Bros</rs> and <rs type="person">Oleksii Polegkyi</rs> for discussions.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_Cr9Hj8B">
					<idno type="grant-number">951911</idno>
					<orgName type="project" subtype="full">AI4Media</orgName>
				</org>
				<org type="funding" xml:id="_SaYavCd">
					<idno type="grant-number">H2020 Programme ICT-48-2020</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,333.39,231.88,224.81,6.97;8,333.39,239.85,225.88,6.97;8,333.39,247.82,159.73,6.97" xml:id="b0">
	<analytic>
		<title level="a" type="main">Pandemic crisis in online media: Quantitative framing analysis on Detik. com&apos;s coverage of Covid-19</title>
		<author>
			<persName coords=""><forename type="first">Justito</forename><surname>Adiprasetio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Annissa</forename><forename type="middle">Winda</forename><surname>Larasati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Jurnal Ilmu Sosial Dan Ilmu Politik</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="153" to="170" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,333.39,255.79,224.81,6.97;8,333.39,263.76,225.88,6.97;8,333.39,271.73,224.81,6.97;8,333.39,279.70,66.99,6.97" xml:id="b1">
	<monogr>
		<title level="m" type="main">RAFT: A real-world few-shot text classification benchmark</title>
		<author>
			<persName coords=""><forename type="first">Neel</forename><surname>Alex</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eli</forename><surname>Lifland</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lewis</forename><surname>Tunstall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Abhishek</forename><surname>Thakur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pegah</forename><surname>Maham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jess</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Emmie</forename><surname>Hine</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carolyn</forename><surname>Ashurst</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Sedille</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexis</forename><surname>Carlier</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.14076</idno>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,333.39,287.67,224.81,6.97;8,333.39,295.64,225.88,6.97;8,333.39,303.61,113.14,6.97" xml:id="b2">
	<monogr>
		<title level="m" type="main">How Did Europe&apos;s Press Cover Covid-19 Vaccination News? A Five-Country Analysis</title>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Alonso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Del</forename><surname>Barrio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Gatica-Perez</surname></persName>
		</author>
		<idno type="DOI">10.1145/3512732.3533588</idno>
		<ptr target="https://doi.org/10.1145/3512732.3533588" />
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
			<biblScope unit="page" from="35" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,333.39,311.58,224.81,6.97;8,333.39,319.55,224.81,6.97;8,333.39,327.52,81.75,6.97" xml:id="b3">
	<monogr>
		<title level="m" type="main">On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?</title>
		<author>
			<persName coords=""><forename type="first">Emily</forename><forename type="middle">M</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Timnit</forename><surname>Gebru</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Angelina</forename><surname>Mcmillan-Major</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shmargaret</forename><surname>Shmitchell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
			<biblScope unit="page" from="610" to="623" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,333.39,335.49,224.81,6.97;8,333.39,343.46,225.88,6.97;8,333.39,351.43,52.14,6.97" xml:id="b4">
	<analytic>
		<title level="a" type="main">Artificial intelligence in journalism: A boon or bane?</title>
		<author>
			<persName coords=""><forename type="first">Santosh</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Biswal</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nikhil</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gouda</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Optimization in machine learning and applications</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="155" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,333.39,359.40,225.88,6.97;8,333.39,367.37,225.58,6.97;8,333.39,375.34,189.06,6.97" xml:id="b5">
	<analytic>
		<title level="a" type="main">Media portrayals of minorities: Muslims in British newspaper headlines, 2001-2012</title>
		<author>
			<persName coords=""><forename type="first">Erik</forename><surname>Bleich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hannah</forename><surname>Stonebraker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hasher</forename><surname>Nisar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rana</forename><surname>Abdelhamid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Ethnic and Migration Studies</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="942" to="962" />
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,333.39,383.31,225.88,6.97;8,333.39,391.28,121.42,6.97" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Bommarito</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><forename type="middle">Martin</forename><surname>Katz</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2212.14402</idno>
		<ptr target="https://doi.org/10.48550/ARXIV.2212.14402" />
		<title level="m">GPT Takes the Bar Exam</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,333.39,399.25,225.58,6.97;8,333.39,407.22,225.99,6.97;8,333.39,415.19,213.01,6.97" xml:id="b7">
	<analytic>
		<title level="a" type="main">Artificial intelligence and journalism</title>
		<author>
			<persName coords=""><forename type="first">Meredith</forename><surname>Broussard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nicholas</forename><surname>Diakopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrea</forename><forename type="middle">L</forename><surname>Guzman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rediet</forename><surname>Abebe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michel</forename><surname>Dupagne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ching-Hua</forename><surname>Chuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journalism &amp; Mass Communication Quarterly</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="673" to="695" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,333.39,423.16,225.58,6.97;8,333.39,431.13,224.81,6.97;8,333.15,439.10,225.06,6.97;8,333.39,447.07,147.90,6.97" xml:id="b8">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName coords=""><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jared</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,333.39,455.04,224.81,6.97;8,333.39,463.01,224.81,6.97;8,333.39,470.98,224.81,6.97;8,333.39,478.95,121.31,6.97" xml:id="b9">
	<analytic>
		<title level="a" type="main">Teaching the computer to code frames in news: Comparing two supervised machine learning approaches to frame analysis</title>
		<author>
			<persName coords=""><forename type="first">Björn</forename><surname>Burscher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daan</forename><surname>Odijk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rens</forename><surname>Vliegenthart</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Claes H De</forename><surname>Vreese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communication Methods and Measures</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="190" to="206" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,333.39,486.92,224.81,6.97;8,333.13,494.89,225.20,6.97;8,333.39,502.86,187.79,6.97" xml:id="b10">
	<analytic>
		<title level="a" type="main">Frames beyond words: Applying cluster and sentiment analysis to news coverage of the nuclear power issue</title>
		<author>
			<persName coords=""><forename type="first">Bjorn</forename><surname>Burscher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rens</forename><surname>Vliegenthart</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Claes H De</forename><surname>Vreese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social Science Computer Review</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="530" to="545" />
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,333.39,510.83,225.88,6.97;8,333.18,518.80,225.79,6.97;8,333.23,526.77,130.32,6.97" xml:id="b11">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Dallas</forename><surname>Card</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Amber</forename><surname>Boydstun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Justin</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Noah</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/P15-2072</idno>
		<ptr target="https://doi.org/10.3115/v1/P15-2072" />
		<title level="m">The Media Frames Corpus: Annotations of Frames Across Issues</title>
		<imprint>
			<date type="published" when="2015-01">2015. 01 2015</date>
			<biblScope unit="page" from="438" to="444" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,333.39,534.74,224.81,6.97;8,333.39,542.71,224.81,6.97;8,333.39,550.68,224.81,6.97;8,333.23,558.65,52.90,6.97" xml:id="b12">
	<analytic>
		<title level="a" type="main">Vaccine hesitancy in the age of coronavirus and fake news: analysis of journalistic sources in the Spanish quality press</title>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Catalan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">-Matamoros</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carlos</forename><surname>Elías</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Environmental Research and Public Health</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page">8136</biblScope>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,333.39,566.63,224.81,6.97;8,333.39,574.60,224.81,6.97;8,333.39,582.57,71.01,6.97" xml:id="b13">
	<analytic>
		<title level="a" type="main">Media and mistrust of vaccines: a content analysis of press headlines</title>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Catalán</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">-Matamoros</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carmen</forename><surname>Peñafiel-Saiz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Revista latina de comunicación social</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="786" to="802" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,333.39,590.54,224.99,6.97;8,333.39,598.51,224.81,6.97;8,333.39,606.48,140.03,6.97" xml:id="b14">
	<analytic>
		<title level="a" type="main">Clarifying journalism&apos;s quantitative turn: A typology for evaluating data journalism, computational journalism, and computer-assisted reporting</title>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Coddington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Digital journalism</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="331" to="348" />
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,333.39,614.45,224.81,6.97;8,333.39,622.42,108.60,6.97" xml:id="b15">
	<analytic>
		<title level="a" type="main">The oppositional framing of bloggers</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Cooper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Doing News Framing Analysis</title>
		<imprint>
			<publisher>Routledge</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="151" to="172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,333.39,630.39,225.58,6.97;8,333.23,638.36,50.20,6.97" xml:id="b16">
	<analytic>
		<title level="a" type="main">GPT-3: What&apos;s it good for?</title>
		<author>
			<persName coords=""><forename type="first">Robert</forename><surname>Dale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="113" to="118" />
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,333.39,646.33,225.99,6.97;8,333.39,654.30,225.99,6.97;8,333.39,662.27,224.81,6.97;8,333.39,670.24,224.97,6.97;8,333.39,678.21,185.44,6.97" xml:id="b17">
	<analytic>
		<title level="a" type="main">To frame is to explain: A deductive frame-analysis of Dutch and French climate change coverage during the annual UN Conferences of the Parties</title>
		<author>
			<persName coords=""><forename type="first">Astrid</forename><surname>Dirikx</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dave</forename><surname>Gelders</surname></persName>
		</author>
		<idno type="DOI">10.1177/0963662509352044</idno>
		<idno type="PMID">21560546</idno>
		<ptr target="https://doi.org/10.1177/0963662509352044" />
	</analytic>
	<monogr>
		<title level="j">Public Understanding of Science</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="732" to="742" />
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,333.39,686.18,225.99,6.97;8,333.39,694.15,224.81,6.97;8,333.39,702.12,223.07,6.97" xml:id="b18">
	<analytic>
		<title level="a" type="main">To frame is to explain: A deductive frameanalysis of Dutch and French climate change coverage during the annual UN Conferences of the Parties</title>
		<author>
			<persName coords=""><forename type="first">Astrid</forename><surname>Dirikx</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dave</forename><surname>Gelders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Public understanding of science</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="732" to="742" />
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,69.23,88.42,225.89,6.97;9,69.23,96.39,225.89,6.97;9,69.23,104.36,108.17,6.97" xml:id="b19">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Zi-Yi</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hiroaki</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhengbao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.08014</idno>
		<title level="m">Gsum: A general framework for guided neural abstractive summarization</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,69.23,112.33,224.81,6.97;9,69.23,120.30,224.81,6.97;9,69.23,128.27,98.60,6.97" xml:id="b20">
	<analytic>
		<title level="a" type="main">The corona chronicles: Framing analysis of online news headlines of the COVID-19 pandemic in Italy</title>
		<author>
			<persName coords=""><forename type="first">Sumayya</forename><surname>Ebrahim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">USA and South Africa. Health SA Gesondheid (Online)</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,69.23,136.24,224.81,6.97;9,68.99,144.21,216.38,6.97" xml:id="b21">
	<monogr>
		<title level="m" type="main">A Feverish Spring: A Comparative Analysis of COVID-19 News Framing in Sweden, the UK, and Egypt</title>
		<author>
			<persName coords=""><forename type="first">Hend</forename><surname>Abdelgaber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ahmed</forename><surname>El-Behary</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,69.23,152.18,225.88,6.97;9,69.23,160.15,179.31,6.97" xml:id="b22">
	<monogr>
		<title level="m" type="main">Framing: Towards clarification of a fractured paradigm. McQuail&apos;s reader in mass communication theory</title>
		<author>
			<persName coords=""><surname>Robert M Entman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993. 1993</date>
			<biblScope unit="volume">390</biblScope>
			<biblScope unit="page">397</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,69.23,168.12,224.81,6.97;9,69.23,176.09,202.39,6.97" xml:id="b23">
	<monogr>
		<title level="m" type="main">Making pre-trained language models better few-shot learners</title>
		<author>
			<persName coords=""><forename type="first">Tianyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.15723</idno>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,69.23,184.06,224.81,6.97;9,69.23,192.03,224.81,6.97;9,69.03,200.00,58.19,6.97" xml:id="b24">
	<analytic>
		<title level="a" type="main">Investigating COVID-19 news across four nations: a topic modeling and sentiment analysis approach</title>
		<author>
			<persName coords=""><forename type="first">Piyush</forename><surname>Ghasiya</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Koji</forename><surname>Okamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ieee Access</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="36645" to="36656" />
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,69.23,207.97,225.99,6.97;9,69.23,215.94,225.88,6.97;9,69.23,223.91,225.63,6.97;9,69.01,231.88,105.17,6.97" xml:id="b25">
	<analytic>
		<title level="a" type="main">A Lens-Mapping Framework for Understanding the Encoding and Decoding of Interpersonal Dispositions in Nonverbal Behavior</title>
		<author>
			<persName coords=""><forename type="first">Robert</forename><surname>Gifford</surname></persName>
		</author>
		<idno type="DOI">10.1037//0022-3514.66.2.398</idno>
		<ptr target="https://doi.org/10.1037//0022-3514.66.2.398" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="398" to="412" />
			<date type="published" when="1994-02">1994. 02 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,69.23,239.85,224.81,6.97;9,69.23,247.82,224.81,6.97;9,69.23,256.42,224.81,6.23;9,69.23,263.76,104.40,6.97" xml:id="b26">
	<analytic>
		<title level="a" type="main">Globalizing BERT-based transformer architectures for long document summarization</title>
		<author>
			<persName coords=""><forename type="first">Quentin</forename><surname>Grail</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julien</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eric</forename><surname>Gaussier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Chapter</title>
		<meeting>the 16th Conference of the European Chapter</meeting>
		<imprint>
			<publisher>the Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1792" to="1810" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,69.23,271.73,224.81,6.97;9,69.23,279.70,225.58,6.97;9,69.23,287.67,24.81,6.97" xml:id="b27">
	<analytic>
		<title level="a" type="main">Automated news summarization using transformers</title>
		<author>
			<persName coords=""><forename type="first">Anushka</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Diksha</forename><surname>Chugh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rahul</forename><surname>Katarya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sustainable Advanced Computing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="249" to="259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,69.23,295.64,225.99,6.97;9,69.23,303.61,224.81,6.97;9,69.03,311.58,45.22,6.97" xml:id="b28">
	<analytic>
		<title level="a" type="main">Finding the data unicorn: A hierarchy of hybridity in data and computational journalism</title>
		<author>
			<persName coords=""><forename type="first">Alfred</forename><surname>Hermida</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mary</forename><surname>Lynn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Young</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Digital Journalism</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="159" to="176" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,69.23,319.55,224.81,6.97;9,69.23,327.52,225.58,6.97;9,69.23,335.49,24.81,6.97" xml:id="b29">
	<analytic>
		<title level="a" type="main">Topic modeling and text analysis for qualitative policy research</title>
		<author>
			<persName coords=""><forename type="first">Karoliina</forename><surname>Isoaho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daria</forename><surname>Gritsenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eetu</forename><surname>Mäkelä</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Policy Studies Journal</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="300" to="324" />
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,69.23,343.46,224.81,6.97;9,69.23,351.43,224.81,6.97;9,69.23,359.40,84.99,6.97" xml:id="b30">
	<analytic>
		<title level="a" type="main">Quantitative analysis of large amounts of journalistic texts using topic modelling</title>
		<author>
			<persName coords=""><forename type="first">Carina</forename><surname>Jacobi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wouter</forename><surname>Van Atteveldt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kasper</forename><surname>Welbers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Digital journalism</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="89" to="106" />
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,69.23,367.37,224.81,6.97;9,69.23,375.34,225.51,6.97;9,69.23,383.31,99.64,6.97" xml:id="b31">
	<analytic>
		<title level="a" type="main">How can we know what language models know?</title>
		<author>
			<persName coords=""><forename type="first">Zhengbao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Frank</forename><forename type="middle">F</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jun</forename><surname>Araki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="423" to="438" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,69.23,391.28,224.81,6.97;9,69.23,399.25,175.99,6.97" xml:id="b32">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Shima</forename><surname>Khanehzar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Turpin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gosia</forename><surname>Mikołajczak</surname></persName>
		</author>
		<title level="m">Modeling Political Framing Across Policy Issues and Contexts</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>In ALTA</note>
</biblStruct>

<biblStruct coords="9,69.23,407.22,224.81,6.97;9,69.23,415.19,224.81,6.97;9,69.03,423.16,41.98,6.97" xml:id="b33">
	<analytic>
		<title level="a" type="main">News framing of the US immigration debate during election years: Focus on generic frames</title>
		<author>
			<persName coords=""><forename type="first">Jeesun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wayne</forename><surname>Wanta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Communication Review</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="89" to="115" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,69.23,431.13,225.99,6.97;9,69.23,439.10,225.88,6.97;9,69.23,447.07,224.81,6.97;9,69.03,455.04,18.66,6.97" xml:id="b34">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rishi</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tony</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dimitris</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dilara</forename><surname>Soylu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michihiro</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Deepak</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yuhuai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ananya</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.09110</idno>
		<title level="m">Holistic evaluation of language models</title>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,69.23,463.01,224.81,6.97;9,69.23,470.98,224.81,6.97;9,69.23,478.95,225.88,6.97;9,69.07,486.92,70.44,6.97" xml:id="b35">
	<monogr>
		<title level="m" type="main">Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing</title>
		<author>
			<persName coords=""><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Weizhe</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jinlan</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhengbao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hiroaki</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2107.13586</idno>
		<ptr target="https://doi.org/10.48550/ARXIV.2107.13586" />
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,69.23,494.89,225.88,6.97;9,69.23,502.86,224.81,6.97;9,69.23,510.83,224.81,6.97;9,69.23,519.43,140.80,6.23" xml:id="b36">
	<analytic>
		<title level="a" type="main">Detecting frames in news headlines and its application to analyzing news framing trends surrounding US gun violence</title>
		<author>
			<persName coords=""><forename type="first">Siyi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lei</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kate</forename><surname>Mays</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Margrit</forename><surname>Betke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Derry</forename><surname>Tanti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wijaya</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd conference on computational natural language learning (CoNLL)</title>
		<meeting>the 23rd conference on computational natural language learning (CoNLL)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,69.23,526.77,225.63,6.97;9,69.03,534.74,225.02,6.97;9,69.23,542.71,156.48,6.97" xml:id="b37">
	<analytic>
		<title level="a" type="main">The Content Analysis of Media Frames: Toward Improving Reliability and Validity</title>
		<author>
			<persName coords=""><forename type="first">Jörg</forename><surname>Matthes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matthias</forename><surname>Kohring</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1460-2466.2008.00384.x</idno>
		<ptr target="https://doi.org/10.1111/j.1460-2466.2008.00384.x" />
	</analytic>
	<monogr>
		<title level="j">Journal of Communication</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<date type="published" when="2008-06">2008. 06 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,69.23,550.68,224.81,6.97;9,69.23,558.65,224.81,6.97;9,69.23,566.63,224.81,6.97;9,69.23,574.60,98.76,6.97" xml:id="b38">
	<analytic>
		<title level="a" type="main">Do We Still Need Human Assessors? Prompt-Based GPT-3 User Simulation in Conversational AI</title>
		<author>
			<persName coords=""><forename type="first">Selina</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Elsweiler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bernd</forename><surname>Ludwig</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Marcos</forename><surname>Fernandez-Pichel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Conference on Conversational User Interfaces</title>
		<meeting>the 4th Conference on Conversational User Interfaces</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,69.23,582.57,224.81,6.97;9,69.23,590.54,224.81,6.97;9,69.23,598.51,86.42,6.97" xml:id="b39">
	<analytic>
		<title level="a" type="main">Social computing for verifying social media content in breaking news</title>
		<author>
			<persName coords=""><surname>Stuart E Middleton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symeon Papadopoulos, and Yiannis Kompatsiaris</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="83" to="89" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,69.23,606.48,225.63,6.97;9,68.99,614.45,225.82,6.97;9,69.23,622.42,56.69,6.97" xml:id="b40">
	<analytic>
		<title level="a" type="main">Our task is to demystify fears&apos;: Analysing newsroom management of automation in journalism</title>
		<author>
			<persName coords=""><forename type="first">Marko</forename><surname>Milosavljević</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Igor</forename><surname>Vobič</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journalism</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="2203" to="2221" />
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,69.23,630.39,224.81,6.97;9,69.23,638.36,225.11,6.97;9,69.23,646.33,57.23,6.97" xml:id="b41">
	<monogr>
		<title level="m" type="main">Human-in-the-Loop Machine Learning: Active Learning and Annotation for Human-centered AI</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Monarch</surname></persName>
		</author>
		<ptr target="https://books.google.ch/books?id=LCh0zQEACAAJ" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,69.23,654.30,224.81,6.97;9,69.23,662.27,224.81,6.97;9,69.23,670.24,65.57,6.97" xml:id="b42">
	<analytic>
		<author>
			<persName coords=""><forename type="first">Tom</forename><surname>Nicholls</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Pepper</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Culpepper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational identification of media frames: Strengths, weaknesses, and opportunities</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="159" to="181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,69.23,678.21,224.81,6.97;9,69.23,686.18,169.47,6.97" xml:id="b43">
	<analytic>
		<title level="a" type="main">Framing analysis: An approach to news discourse</title>
		<author>
			<persName coords=""><forename type="first">Zhongdang</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gerald</forename><forename type="middle">M</forename><surname>Kosicki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Political communication</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="55" to="75" />
			<date type="published" when="1993">1993. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,69.23,694.15,224.81,6.97;9,69.23,702.12,160.19,6.97" xml:id="b44">
	<monogr>
		<title level="m" type="main">Zero-shot text classification with generative language models</title>
		<author>
			<persName coords=""><forename type="first">Raul</forename><surname>Puri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bryan</forename><surname>Catanzaro</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.10165</idno>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,333.39,88.42,224.81,6.97;9,333.39,96.39,182.71,6.97" xml:id="b45">
	<monogr>
		<title level="m" type="main">Learning how to ask: Querying lms with mixtures of soft prompts</title>
		<author>
			<persName coords=""><forename type="first">Guanghui</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.06599</idno>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,333.39,104.36,225.88,6.97;9,333.39,112.33,223.11,6.97" xml:id="b46">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Rabindra</forename><surname>Lamsal</surname></persName>
		</author>
		<ptr target="https://huggingface.co/rabindralamsal/finetuned-bertweet-sentiment-analysis" />
		<title level="m">Sentiment Analysis of English Tweets with BERTsent</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,333.39,120.30,225.58,6.97;9,333.39,128.27,224.81,6.97;9,333.23,136.24,36.69,6.97" xml:id="b47">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName coords=""><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OpenAI blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,333.39,144.21,225.89,6.97;9,333.39,152.18,225.88,6.97;9,333.39,160.15,225.89,6.97;9,333.39,168.12,116.23,6.97" xml:id="b48">
	<analytic>
		<title level="a" type="main">Fake News Classification using transformer based enhanced LSTM and BERT</title>
		<author>
			<persName coords=""><forename type="first">Nishant</forename><surname>Rai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Deepika</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Naman</forename><surname>Kaushik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chandan</forename><surname>Raj</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ahad</forename><surname>Ali</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ijcce.2022.03.003</idno>
		<ptr target="https://doi.org/10.1016/j.ijcce.2022.03.003" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Cognitive Computing in Engineering</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="98" to="105" />
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,333.39,176.09,224.81,6.97;9,333.39,184.06,128.20,6.97" xml:id="b49">
	<analytic>
		<title level="a" type="main">Framing of the Covid-19 pandemic and its organizational predictors</title>
		<author>
			<persName coords=""><forename type="first">Frida</forename><forename type="middle">V</forename><surname>Rodelo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cuadernos. info</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="91" to="112" />
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,333.39,192.03,224.81,6.97;9,333.39,200.00,224.81,6.97;9,333.39,207.97,224.81,6.97;9,333.39,215.94,129.86,6.97" xml:id="b50">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Le</forename><surname>Teven</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Angela</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ellie</forename><surname>Akiki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Suzana</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Ilić</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Roman</forename><surname>Hesslow</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexandra</forename><surname>Castagné</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">François</forename><surname>Sasha Luccioni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matthias</forename><surname>Yvon</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Gallé</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.05100</idno>
		<title level="m">Bloom: A 176b-parameter open-access multilingual language model</title>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,333.39,223.91,224.81,6.97;9,333.15,231.88,225.82,6.97;9,333.39,239.85,170.59,6.97" xml:id="b51">
	<analytic>
		<title level="a" type="main">Framing European Politics: A Content Analysis of Press and Television News</title>
		<author>
			<persName coords=""><forename type="first">Holli</forename><surname>Semetko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Patti</forename><surname>Valkenburg</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1460-2466.2000.tb02843.x</idno>
		<ptr target="https://doi.org/10.1111/j.1460-2466.2000.tb02843.x" />
	</analytic>
	<monogr>
		<title level="j">Journal of Communication</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="93" to="109" />
			<date type="published" when="2000-06">2000. 06 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,333.39,247.82,225.99,6.97;9,333.39,255.79,224.81,6.97;9,333.16,263.76,226.11,6.97;9,333.39,271.73,108.23,6.97" xml:id="b52">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Richard</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sam</forename><surname>Christopher H Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Charles</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Subhro</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Emmanouil</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adam</forename><surname>Antonios Platanios</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dan</forename><surname>Pauls</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jason</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benjamin</forename><surname>Eisner</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Van Durme</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.08768</idno>
		<title level="m">Constrained language models yield few-shot semantic parsers</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,333.39,279.70,225.99,6.97;9,333.39,287.67,225.99,6.97;9,333.39,295.64,225.89,6.97;9,333.39,303.61,108.55,6.97" xml:id="b53">
	<analytic>
		<title level="a" type="main">Computer Supported Collaborative Work trends on Media Organizations: Mixing Qualitative and Quantitative Approaches</title>
		<author>
			<persName coords=""><forename type="first">Efstathios</forename><surname>Sidiropoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andreas</forename><surname>Veglis</surname></persName>
		</author>
		<idno type="DOI">10.11114/smc.v5i1.2279</idno>
		<ptr target="https://doi.org/10.11114/smc.v5i1.2279" />
	</analytic>
	<monogr>
		<title level="j">Studies in Media and Communication</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">04</biblScope>
			<biblScope unit="page">63</biblScope>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,333.39,311.58,224.99,6.97;9,333.39,319.55,223.05,6.97" xml:id="b54">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Emma</forename><surname>Strubell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ananya</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.02243</idno>
		<title level="m">Energy and policy considerations for deep learning in NLP</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,333.39,327.52,224.81,6.97;9,333.39,335.49,224.81,6.97;9,333.39,343.46,90.94,6.97" xml:id="b55">
	<monogr>
		<title level="m" type="main">Understanding the capabilities, limitations, and societal impact of large language models</title>
		<author>
			<persName coords=""><forename type="first">Alex</forename><surname>Tamkin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Miles</forename><surname>Brundage</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jack</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Deep</forename><surname>Ganguli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.02503</idno>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,333.39,351.43,225.88,6.97;9,333.39,359.40,108.66,6.97" xml:id="b56">
	<monogr>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Trieu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Quoc V</forename><surname>Trinh</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.02847</idno>
		<title level="m">A simple method for commonsense reasoning</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,333.39,367.37,224.81,6.97;9,333.39,375.34,225.88,6.97;9,333.39,383.31,198.04,6.97" xml:id="b57">
	<analytic>
		<title level="a" type="main">Multimodal few-shot learning with frozen language models</title>
		<author>
			<persName coords=""><forename type="first">Maria</forename><surname>Tsimpoukelli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jacob</forename><forename type="middle">L</forename><surname>Menick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Serkan</forename><surname>Cabi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Oriol</forename><surname>Eslami</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Felix</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Hill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="200" to="212" />
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,333.39,391.28,224.81,6.97;9,333.39,399.25,168.23,6.97" xml:id="b58">
	<analytic>
		<title level="a" type="main">The social influence model of technology adoption</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sandra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Prashant</forename><surname>Vannoy</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Palvia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="149" to="153" />
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,333.39,407.22,224.81,6.97;9,333.39,415.19,225.88,6.97;9,333.39,423.16,153.89,6.97" xml:id="b59">
	<analytic>
		<title level="a" type="main">Topic modeling for frame analysis: A study of media debates on climate change in India and USA</title>
		<author>
			<persName coords=""><forename type="first">Tuukka</forename><surname>Ylä-Anttila</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Veikko</forename><surname>Eranti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Anna</forename><surname>Kukkonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Global Media and Communication</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="91" to="112" />
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
